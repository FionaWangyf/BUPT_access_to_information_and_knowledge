#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯äº¤äº’çš„ä¿¡æ¯æ£€ç´¢+ä¿¡æ¯æŠ½å–é›†æˆç³»ç»Ÿ
æ–‡ä»¶ä½ç½®ï¼šinteractive_integrated_system.py
"""

import sys
import os
import json
import time
from typing import List, Dict, Any, Optional
sys.path.append('src')

# å¯¼å…¥ç°æœ‰çš„æ£€ç´¢ç³»ç»Ÿ
from src.retrieval.search_engine import EnhancedSearchEngine

# å¯¼å…¥æŠ½å–ç³»ç»Ÿ
from src.extraction.extraction_manager import ExtractionManager

class InteractiveIntegratedSystem:
    """å¯äº¤äº’çš„ä¿¡æ¯æ£€ç´¢+ä¿¡æ¯æŠ½å–é›†æˆç³»ç»Ÿ"""
    
    def __init__(self, data_file: str):
        self.data_file = data_file
        self.search_engine = None
        self.extraction_manager = None
        self.is_initialized = False
        
        # æ“ä½œæ¨¡å¼
        self.current_mode = "integrated"  # integrated, search_only, extract_only
        
    def initialize(self) -> bool:
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            print("ğŸ”§ åˆå§‹åŒ–é›†æˆç³»ç»Ÿ...")
            
            # 1. åˆå§‹åŒ–æ£€ç´¢å¼•æ“
            print("ğŸ“š åˆå§‹åŒ–ä¿¡æ¯æ£€ç´¢å¼•æ“...")
            self.search_engine = EnhancedSearchEngine(self.data_file)
            if not self.search_engine.initialize():
                print("âŒ æ£€ç´¢å¼•æ“åˆå§‹åŒ–å¤±è´¥")
                return False
            
            # 2. åˆå§‹åŒ–æŠ½å–ç®¡ç†å™¨
            print("ğŸ” åˆå§‹åŒ–ä¿¡æ¯æŠ½å–å¼•æ“...")
            config = {
                'enable_regex_extractor': True,
                'regex_confidence_threshold': 0.6,
                'merge_duplicate_entities': True,
                'max_entities_per_type': 30,
                'enable_cache': True,
            }
            
            self.extraction_manager = ExtractionManager(config)
            if not self.extraction_manager.initialize():
                print("âŒ æŠ½å–ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥")
                return False
            
            self.is_initialized = True
            print("âœ… é›†æˆç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def search_only(self, query: str, top_k: int = 10):
        """çº¯ä¿¡æ¯æ£€ç´¢æ¨¡å¼ï¼ˆä½œä¸š2åŠŸèƒ½ï¼‰"""
        print(f"\nğŸ” ã€ä¿¡æ¯æ£€ç´¢æ¨¡å¼ã€‘æŸ¥è¯¢: '{query}'")
        print("ç›®æ ‡ï¼šæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£")
        
        start_time = time.time()
        results = self.search_engine.search(query, top_k)
        search_time = time.time() - start_time
        
        print(f"\nğŸ“Š æ£€ç´¢ç»“æœ (è€—æ—¶ {search_time:.3f}ç§’):")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. ã€ç›¸ä¼¼åº¦: {result.similarity:.3f}ã€‘")
            print(f"   æ ‡é¢˜: {result.title}")
            print(f"   å†…å®¹é¢„è§ˆ: {result.content[:150]}...")
            print(f"   URL: {result.url}")
            if hasattr(result, 'matched_terms') and result.matched_terms:
                print(f"   åŒ¹é…è¯æ±‡: {', '.join(result.matched_terms)}")
        
        return results
    
    def extract_only(self, text: str):
        """çº¯ä¿¡æ¯æŠ½å–æ¨¡å¼ï¼ˆä½œä¸š3åŠŸèƒ½ï¼‰"""
        print(f"\nğŸ”¬ ã€ä¿¡æ¯æŠ½å–æ¨¡å¼ã€‘")
        print("ç›®æ ‡ï¼šä»æ–‡æœ¬ä¸­æŠ½å–ç»“æ„åŒ–å®ä½“")
        print(f"è¾“å…¥æ–‡æœ¬: {text[:100]}...")
        
        start_time = time.time()
        results = self.extraction_manager.extract_from_text(text, 1, "input")
        extract_time = time.time() - start_time
        
        print(f"\nğŸ“Š æŠ½å–ç»“æœ (è€—æ—¶ {extract_time:.3f}ç§’):")
        
        if not results:
            print("æœªæ‰¾åˆ°ä»»ä½•å®ä½“")
            return results
        
        print(f"æŠ½å–åˆ° {len(results)} ä¸ªå®ä½“:")
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        by_type = {}
        for result in results:
            if result.entity_type not in by_type:
                by_type[result.entity_type] = []
            by_type[result.entity_type].append(result)
        
        for entity_type, entities in by_type.items():
            print(f"\nğŸ·ï¸ {entity_type.upper()} ({len(entities)} ä¸ª):")
            for entity in sorted(entities, key=lambda x: x.confidence, reverse=True):
                print(f"   âœ“ {entity.entity_value} (ç½®ä¿¡åº¦: {entity.confidence:.3f})")
                print(f"     ä¸Šä¸‹æ–‡: {entity.context[:80]}...")
        
        return results
    
    def integrated_search_extract(self, query: str, top_k: int = 5):
        """é›†æˆæ¨¡å¼ï¼šæ£€ç´¢+æŠ½å–"""
        print(f"\nğŸ¯ ã€é›†æˆæ¨¡å¼ã€‘æŸ¥è¯¢: '{query}'")
        print("ç›®æ ‡ï¼šå…ˆæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œå†ä»æ–‡æ¡£ä¸­æŠ½å–å®ä½“")
        
        # ç¬¬ä¸€æ­¥ï¼šä¿¡æ¯æ£€ç´¢
        print("\nğŸ“‹ æ­¥éª¤1: ä¿¡æ¯æ£€ç´¢")
        search_start = time.time()
        search_results = self.search_engine.search(query, top_k)
        search_time = time.time() - search_start
        
        print(f"âœ… æ£€ç´¢å®Œæˆ: æ‰¾åˆ° {len(search_results)} ä¸ªç›¸å…³æ–‡æ¡£ (è€—æ—¶ {search_time:.3f}ç§’)")
        
        if not search_results:
            print("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡ŒæŠ½å–")
            return
        
        # ç¬¬äºŒæ­¥ï¼šä¿¡æ¯æŠ½å–
        print("\nğŸ“‹ æ­¥éª¤2: ä¿¡æ¯æŠ½å–")
        extract_start = time.time()
        all_entities = []
        doc_entities = {}
        
        for i, doc in enumerate(search_results):
            print(f"  æ­£åœ¨æŠ½å–æ–‡æ¡£ {i+1}/{len(search_results)}...")
            
            # ä»æ ‡é¢˜å’Œå†…å®¹ç‰‡æ®µæŠ½å–
            doc_text = f"{doc.title}. {doc.content[:500]}"
            entities = self.extraction_manager.extract_from_text(doc_text, doc.doc_id, "search_result")
            
            all_entities.extend(entities)
            doc_entities[i] = {
                'doc_info': doc,
                'entities': entities
            }
        
        extract_time = time.time() - extract_start
        total_time = search_time + extract_time
        
        print(f"âœ… æŠ½å–å®Œæˆ: ä» {len(search_results)} ä¸ªæ–‡æ¡£ä¸­æŠ½å– {len(all_entities)} ä¸ªå®ä½“ (è€—æ—¶ {extract_time:.3f}ç§’)")
        
        # ç¬¬ä¸‰æ­¥ï¼šç»“æœå±•ç¤º
        print(f"\nğŸ“Š é›†æˆç»“æœæ‘˜è¦ (æ€»è€—æ—¶ {total_time:.3f}ç§’):")
        
        # ç»Ÿè®¡æ‰€æœ‰å®ä½“
        entity_stats = {}
        for entity in all_entities:
            entity_type = entity.entity_type
            if entity_type not in entity_stats:
                entity_stats[entity_type] = []
            entity_stats[entity_type].append(entity)
        
        print(f"  ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"    æ£€ç´¢æ–‡æ¡£: {len(search_results)} ç¯‡")
        print(f"    æŠ½å–å®ä½“: {len(all_entities)} ä¸ª")
        print(f"    å®ä½“ç±»å‹: {len(entity_stats)} ç§")
        
        # æ˜¾ç¤ºå„ç±»å‹çƒ­é—¨å®ä½“
        print(f"\nğŸ”¥ çƒ­é—¨å®ä½“ (æŒ‰ç±»å‹):")
        for entity_type, entities in entity_stats.items():
            # ç»Ÿè®¡å®ä½“å‡ºç°é¢‘æ¬¡
            entity_counts = {}
            for entity in entities:
                value = entity.entity_value
                if value not in entity_counts:
                    entity_counts[value] = {'count': 0, 'confidence': entity.confidence}
                entity_counts[value]['count'] += 1
                entity_counts[value]['confidence'] = max(entity_counts[value]['confidence'], entity.confidence)
            
            # æŒ‰é¢‘æ¬¡æ’åºï¼Œæ˜¾ç¤ºå‰3ä¸ª
            top_entities = sorted(entity_counts.items(), key=lambda x: (x[1]['count'], x[1]['confidence']), reverse=True)[:3]
            
            print(f"  ğŸ·ï¸ {entity_type.upper()}:")
            for entity_value, stats in top_entities:
                print(f"     {entity_value} (å‡ºç°{stats['count']}æ¬¡, æœ€é«˜ç½®ä¿¡åº¦{stats['confidence']:.3f})")
        
        # æ˜¾ç¤ºæ¯ä¸ªæ–‡æ¡£çš„è¯¦ç»†ç»“æœ
        print(f"\nğŸ“„ åˆ†æ–‡æ¡£ç»“æœ:")
        for i, doc_data in doc_entities.items():
            doc_info = doc_data['doc_info']
            entities = doc_data['entities']
            
            print(f"\n  æ–‡æ¡£ {i+1}: {doc_info.title[:60]}...")
            print(f"    ç›¸ä¼¼åº¦: {doc_info.similarity:.3f}")
            print(f"    æŠ½å–å®ä½“: {len(entities)} ä¸ª")
            
            if entities:
                # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
                doc_by_type = {}
                for entity in entities:
                    if entity.entity_type not in doc_by_type:
                        doc_by_type[entity.entity_type] = []
                    doc_by_type[entity.entity_type].append(entity.entity_value)
                
                for entity_type, values in doc_by_type.items():
                    unique_values = list(set(values))[:3]  # å»é‡ï¼Œæ˜¾ç¤ºå‰3ä¸ª
                    print(f"      {entity_type}: {', '.join(unique_values)}")
        
        return {
            'search_results': search_results,
            'all_entities': all_entities,
            'entity_stats': entity_stats,
            'processing_time': {
                'search_time': search_time,
                'extract_time': extract_time,
                'total_time': total_time
            }
        }
    
    def interactive_mode(self):
        """äº¤äº’å¼æ¨¡å¼"""
        print("ğŸ¯ äº¤äº’å¼ä¿¡æ¯æ£€ç´¢+æŠ½å–ç³»ç»Ÿ")
        print("=" * 60)
        
        # æ˜¾ç¤ºåŠŸèƒ½ä»‹ç»
        self._show_introduction()
        
        while True:
            try:
                print(f"\nå½“å‰æ¨¡å¼: {self._get_mode_description()}")
                user_input = input("è¯·è¾“å…¥å‘½ä»¤æˆ–æŸ¥è¯¢ (è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©): ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†å‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                elif user_input.lower() == 'help':
                    self._show_help()
                    continue
                
                elif user_input.lower().startswith('mode '):
                    mode = user_input[5:].strip()
                    self._change_mode(mode)
                    continue
                
                elif user_input.lower() == 'demo':
                    self._run_demo()
                    continue
                
                elif user_input.lower() == 'stats':
                    self._show_stats()
                    continue
                
                elif user_input.lower().startswith('extract '):
                    text = user_input[8:].strip()
                    self.extract_only(text)
                    continue
                
                # å¤„ç†æŸ¥è¯¢
                if self.current_mode == "search_only":
                    self.search_only(user_input)
                elif self.current_mode == "extract_only":
                    print("âŒ æŠ½å–æ¨¡å¼éœ€è¦ä½¿ç”¨ 'extract æ–‡æœ¬å†…å®¹' æ ¼å¼")
                else:  # integrated mode
                    self.integrated_search_extract(user_input)
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
    
    def _show_introduction(self):
        """æ˜¾ç¤ºç³»ç»Ÿä»‹ç»"""
        print("\nğŸ“– ç³»ç»ŸåŠŸèƒ½:")
        print("  ğŸ” ä¿¡æ¯æ£€ç´¢ (ä½œä¸š2): ä»æ–‡æ¡£åº“ä¸­æ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£")
        print("  ğŸ”¬ ä¿¡æ¯æŠ½å– (ä½œä¸š3): ä»æ–‡æ¡£ä¸­æŠ½å–ç»“æ„åŒ–å®ä½“ä¿¡æ¯")
        print("  ğŸ¯ é›†æˆæ¨¡å¼: å…ˆæ£€ç´¢åæŠ½å–ï¼Œè·å¾—ç»“æ„åŒ–çŸ¥è¯†")
        
        print("\nğŸ’¡ ä½¿ç”¨åœºæ™¯å¯¹æ¯”:")
        print("  ä¿¡æ¯æ£€ç´¢: 'æƒ³äº†è§£å…³äºBidençš„æ–°é—»' â†’ è¿”å›ç›¸å…³æ–°é—»æ–‡æ¡£")
        print("  ä¿¡æ¯æŠ½å–: 'ä»è¿™æ®µæ–‡æœ¬ä¸­æ‰¾å‡ºæ‰€æœ‰äººåå’Œåœ°å' â†’ è¿”å›å®ä½“åˆ—è¡¨")
        print("  é›†æˆæ¨¡å¼: 'å…³äºUkraineçš„æ–°é—»ä¸­æ¶‰åŠå“ªäº›äººç‰©å’Œé‡‘é¢?' â†’ æ£€ç´¢+æŠ½å–")
    
    def _show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\nğŸ“‹ å‘½ä»¤å¸®åŠ©:")
        print("  ç›´æ¥è¾“å…¥æŸ¥è¯¢ - æ ¹æ®å½“å‰æ¨¡å¼æ‰§è¡Œæœç´¢æˆ–æŠ½å–")
        print("  extract æ–‡æœ¬å†…å®¹ - å¯¹æŒ‡å®šæ–‡æœ¬è¿›è¡Œå®ä½“æŠ½å–")
        print("  mode search - åˆ‡æ¢åˆ°çº¯æ£€ç´¢æ¨¡å¼")
        print("  mode extract - åˆ‡æ¢åˆ°çº¯æŠ½å–æ¨¡å¼") 
        print("  mode integrated - åˆ‡æ¢åˆ°é›†æˆæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰")
        print("  demo - è¿è¡Œé¢„è®¾æ¼”ç¤º")
        print("  stats - æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡")
        print("  help - æ˜¾ç¤ºæ­¤å¸®åŠ©")
        print("  quit - é€€å‡ºç¨‹åº")
        
        print("\nğŸ¯ æ¨èæŸ¥è¯¢ç¤ºä¾‹:")
        print("  NPR funding lawsuit - æ”¿æ²»ã€æ³•å¾‹ã€é‡‘é¢å®ä½“ä¸°å¯Œ")
        print("  Biden Ukraine aid - äººåã€åœ°åã€é‡‘é¢")
        print("  Katherine Maher testimony - äººåã€ç»„ç»‡ã€æ—¶é—´")
        print("  China trade tariffs - å›½å®¶ã€ç»æµã€ç™¾åˆ†æ¯”")
    
    def _get_mode_description(self):
        """è·å–å½“å‰æ¨¡å¼æè¿°"""
        descriptions = {
            'search_only': 'ğŸ” çº¯æ£€ç´¢æ¨¡å¼ (ä½œä¸š2åŠŸèƒ½)',
            'extract_only': 'ğŸ”¬ çº¯æŠ½å–æ¨¡å¼ (ä½œä¸š3åŠŸèƒ½)',
            'integrated': 'ğŸ¯ é›†æˆæ¨¡å¼ (æ£€ç´¢+æŠ½å–)'
        }
        return descriptions.get(self.current_mode, 'æœªçŸ¥æ¨¡å¼')
    
    def _change_mode(self, mode: str):
        """åˆ‡æ¢æ“ä½œæ¨¡å¼"""
        valid_modes = ['search', 'extract', 'integrated']
        mode_map = {
            'search': 'search_only',
            'extract': 'extract_only', 
            'integrated': 'integrated'
        }
        
        if mode in valid_modes:
            self.current_mode = mode_map[mode]
            print(f"âœ… å·²åˆ‡æ¢åˆ°: {self._get_mode_description()}")
        else:
            print(f"âŒ æ— æ•ˆæ¨¡å¼ã€‚æœ‰æ•ˆé€‰é¡¹: {', '.join(valid_modes)}")
    
    def _run_demo(self):
        """è¿è¡Œæ¼”ç¤º"""
        demo_queries = [
            "NPR funding lawsuit",
            "Biden Ukraine aid", 
            "Katherine Maher testimony"
        ]
        
        print("\nğŸ¬ è¿è¡Œé¢„è®¾æ¼”ç¤º...")
        for query in demo_queries:
            print(f"\n{'='*50}")
            self.integrated_search_extract(query, top_k=3)
            time.sleep(2)
    
    def _show_stats(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡"""
        print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
        
        if self.extraction_manager:
            extract_stats = self.extraction_manager.get_summary_statistics()
            print(f"  ğŸ”¬ æŠ½å–ç³»ç»Ÿ:")
            print(f"    å¤„ç†æ–‡æ¡£: {extract_stats['total_documents_processed']}")
            print(f"    æ€»æŠ½å–æ•°: {extract_stats['total_extractions']}")
            print(f"    å¹³å‡ç½®ä¿¡åº¦: {extract_stats['average_confidence']:.3f}")
        
        if self.search_engine:
            search_info = self.search_engine.get_system_info()
            print(f"  ğŸ” æ£€ç´¢ç³»ç»Ÿ:")
            print(f"    çŠ¶æ€: {search_info.get('ç³»ç»ŸçŠ¶æ€', 'æœªçŸ¥')}")
            if 'æ–‡æ¡£ç»Ÿè®¡' in search_info:
                print(f"    æ–‡æ¡£æ•°: {search_info['æ–‡æ¡£ç»Ÿè®¡'].get('æ€»æ–‡æ¡£æ•°', 'æœªçŸ¥')}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨äº¤äº’å¼é›†æˆç³»ç»Ÿ")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    system = InteractiveIntegratedSystem("data/npr_articles.json")
    if not system.initialize():
        print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
        return 1
    
    # å¯åŠ¨äº¤äº’æ¨¡å¼
    system.interactive_mode()
    
    return 0

if __name__ == "__main__":
    exit(main())